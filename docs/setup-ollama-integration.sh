#!/bin/bash
# Setup Ollama Integration with LiteLLM and Google Assistant AI
# Run this script to complete the Ollama setup

set -e

echo "üéØ Setting up Ollama Integration..."
echo ""

# 1. Check Ollama is running
echo "1Ô∏è‚É£ Checking Ollama status..."
if systemctl is-active --quiet ollama; then
    echo "   ‚úÖ Ollama is running"
else
    echo "   ‚ùå Ollama is not running"
    echo "   Starting Ollama..."
    sudo systemctl start ollama
    sleep 2
fi

# 2. List installed models
echo ""
echo "2Ô∏è‚É£ Installed Ollama models:"
ollama list

# 3. Test Ollama API
echo ""
echo "3Ô∏è‚É£ Testing Ollama API..."
if curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "   ‚úÖ Ollama API is responding"
else
    echo "   ‚ùå Ollama API not responding"
    exit 1
fi

# 4. Backup existing LiteLLM config
echo ""
echo "4Ô∏è‚É£ Backing up LiteLLM config..."
cp ~/.config/litellm/config.yaml ~/.config/litellm/config.yaml.backup-$(date +%Y%m%d-%H%M%S)
echo "   ‚úÖ Backup created"

# 5. Install new LiteLLM config
echo ""
echo "5Ô∏è‚É£ Installing new LiteLLM config with Ollama models..."
cp /home/jbyrd/ai-dev-workspace/personal-projects/google-assistant-ai/docs/OLLAMA-LITELLM-CONFIG.yaml \
   ~/.config/litellm/config.yaml
echo "   ‚úÖ Config installed"

# 6. Restart LiteLLM service
echo ""
echo "6Ô∏è‚É£ Restarting LiteLLM service..."
systemctl --user restart pai-litellm
sleep 3

if systemctl --user is-active --quiet pai-litellm; then
    echo "   ‚úÖ LiteLLM restarted successfully"
else
    echo "   ‚ùå LiteLLM failed to start"
    echo "   Checking logs..."
    journalctl --user -u pai-litellm -n 20 --no-pager
    exit 1
fi

# 7. Test LiteLLM with Ollama model
echo ""
echo "7Ô∏è‚É£ Testing LiteLLM ‚Üí Ollama integration..."
RESPONSE=$(curl -s -X POST http://localhost:4000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer sk-pai-hatter-red-hat-ai-models-2025" \
  -d '{
    "model": "mistral-7b-instruct",
    "messages": [{"role": "user", "content": "Say hello in exactly 3 words"}],
    "max_tokens": 20
  }')

if echo "$RESPONSE" | grep -q "error"; then
    echo "   ‚ùå Error testing LiteLLM:"
    echo "$RESPONSE" | python3 -m json.tool
    exit 1
else
    echo "   ‚úÖ LiteLLM ‚Üí Ollama working!"
    echo "   Response: $(echo "$RESPONSE" | python3 -c "import sys, json; print(json.load(sys.stdin)['choices'][0]['message']['content'])")"
fi

# 8. Update Google Assistant AI container environment
echo ""
echo "8Ô∏è‚É£ Updating Google Assistant AI configuration..."
cd /home/jbyrd/ai-dev-workspace/personal-projects/google-assistant-ai

# Update docker-compose environment
sed -i 's/LITELLM_MODEL=.*/LITELLM_MODEL=mistral-7b-instruct/' docker-compose.yml
echo "   ‚úÖ Updated docker-compose.yml to use mistral-7b-instruct"

# 9. Rebuild and restart container
echo ""
echo "9Ô∏è‚É£ Rebuilding and restarting Google Assistant AI container..."
podman-compose down
podman build -t google-assistant-ai:latest .
podman-compose up -d

echo ""
echo "üéâ Setup Complete!"
echo ""
echo "üìä Summary:"
echo "  ‚Ä¢ Ollama: Running on localhost:11434"
echo "  ‚Ä¢ LiteLLM: Running on localhost:4000"
echo "  ‚Ä¢ Models: mistral-7b-instruct (default), phi3-mini, llama3.2-3b"
echo "  ‚Ä¢ Google Assistant AI: Running in container"
echo ""
echo "üß™ Test the integration:"
echo "  curl http://localhost:5001/health"
echo ""
echo "üìù View logs:"
echo "  journalctl --user -u pai-litellm -f     # LiteLLM"
echo "  podman logs -f google-assistant-ai      # Assistant"
echo ""


